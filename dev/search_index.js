var documenterSearchIndex = {"docs":
[{"location":"api/#API-reference","page":"API reference","title":"API reference","text":"","category":"section"},{"location":"api/#Types","page":"API reference","title":"Types","text":"","category":"section"},{"location":"api/#RadialCalderon.ForwardProblem","page":"API reference","title":"RadialCalderon.ForwardProblem","text":"struct ForwardProblem\n\nContainer for the forward Calderon problem\n\nFields\n\nn::Integer: number of annuli\nradii::Vector: inner radii\n\n\n\n\n\n","category":"type"},{"location":"api/#RadialCalderon.ConvexCalderonProblem","page":"API reference","title":"RadialCalderon.ConvexCalderonProblem","text":"struct ConvexCalderonProblem\n\nContainer for the convex nonlinear SDP problem\n\nFields\n\nc::Vector: weight vector\na::Number: conductivity lower bound\nb::Number: conductivity upper bound\nobs::Vector: observations\nforward::ForwardProblem: forward problem\n\n\n\n\n\n","category":"type"},{"location":"api/#Resolution","page":"API reference","title":"Resolution","text":"","category":"section"},{"location":"api/#RadialCalderon.build_c_estimation_problem","page":"API reference","title":"RadialCalderon.build_c_estimation_problem","text":"build_c_estimation_problem(\n    σ,\n    a,\n    b,\n    m,\n    forward;\n    max_last_coord\n)\n\n\nBuild the feasibility problem used to estimate the weight vector\n\n\n\n\n\n","category":"function"},{"location":"api/#RadialCalderon.build_nonlinear_sdp","page":"API reference","title":"RadialCalderon.build_nonlinear_sdp","text":"build_nonlinear_sdp(problem, σ_init; reg_param)\n\n\nBuild the convex nonlinear SDP associated to the input Calderon problem\n\n\n\n\n\n","category":"function"},{"location":"examples/forward/#Evaluating-the-forward-map-and-its-derivatives","page":"Forward map","title":"Evaluating the forward map and its derivatives","text":"","category":"section"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"Here we show how to evaluate the forward map associated to the Calderon problem with radial piecewise constant conductivities. We also show how to evaluate its derivatives via automatic differentiation.","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"using RadialCalderon","category":"page"},{"location":"examples/forward/#Setting","page":"Forward map","title":"Setting","text":"","category":"section"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"We define the forward problem. There are three annuli with the inner radii being 0.5 and 0.25.","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"n = 3\nr = [0.5, 0.25]\nforward = ForwardProblem(r);\nnothing #hide","category":"page"},{"location":"examples/forward/#Forward-map","page":"Forward map","title":"Forward map","text":"","category":"section"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"We define the (diagonal) Neumann-to-Dirichlet map associated to the boundary data (mathrmcos(jtheta))_1leq jleq m.","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"m = 5\nλ(j, σ) = forward_map(forward, j, σ)\nΛ(σ) = [λ(j, σ) for j in 1:m];\nnothing #hide","category":"page"},{"location":"examples/forward/#Derivatives","page":"Forward map","title":"Derivatives","text":"","category":"section"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"The first and second order derivatives of Lambda can be computed via automatic differentiation. The automatic differentiation backend (here ForwardDiff) can be changed easily thanks to the DifferentiationInterface package.","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"using DifferentiationInterface\nimport ForwardDiff\n\nbackend = AutoForwardDiff()\n\ndΛ(σ) = jacobian(Λ, backend, σ)  # Jacobian of the forward map\ngrad_λ(j, σ) = gradient(σ -> λ(j, σ), backend, σ)  # gradient of the j-th output\nhess_λ(j, σ) = hessian(σ -> λ(j, σ), backend, σ)  # Hessian of the j-th output\n\ndΛ(ones(n))","category":"page"},{"location":"examples/forward/#Closed-form-expression","page":"Forward map","title":"Closed form expression","text":"","category":"section"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"When n=3 and the conductivity is equal to 1 on the outermost annulus, the forward map has the following closed form expression (Harrach, 2023):","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"λ_j(σ_1σ_2)=fracc_j+d_jj(c_j-d_j)","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"where","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"c_j=(1σ_1+1)(σ_1+σ_2) + (1σ_1-1)(σ_1-σ_2)r_2^2jr_1^2j","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"d_j=(1σ_1-1)(σ_1+σ_2)r_1^2j + (1σ_1+1)(σ_1-σ_2)r_2^2j","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"We check the consistency of the implemented forward map with this formula.","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"σ1 = 1.5\nσ2 = 0.5\nσ = [1.0, σ1, σ2]\n\nc(j) = (1/σ1+1)*(σ1+σ2) + (1/σ1-1)*(σ1-σ2)*r[2]^(2*j)/r[1]^(2*j)\nd(j) = (1/σ1-1)*(σ1+σ2)*r[1]^(2*j) + (1/σ1+1)*(σ1-σ2)*r[2]^(2*j)\n\n@info forward_map(forward, 1, σ) ≈ (c(1)+d(1)) / (c(1)-d(1))\n@info forward_map(forward, 2, σ) ≈ (c(2)+d(2)) / (2*(c(2)-d(2)))\n@info forward_map(forward, 3, σ) ≈ (c(3)+d(3)) / (3*(c(3)-d(3)))","category":"page"},{"location":"examples/forward/#References","page":"Forward map","title":"References","text":"","category":"section"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"Harrach, B. (2023). The Calderón Problem with Finitely Many Unknowns Is Equivalent to Convex Semidefinite Optimization. SIAM Journal on Mathematical Analysis, 5666–5684.\n\n\n\n","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"","category":"page"},{"location":"examples/forward/","page":"Forward map","title":"Forward map","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/least_squares/#Reconstruction-via-nonlinear-least-squares","page":"Least squares","title":"Reconstruction via nonlinear least squares","text":"","category":"section"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"In this tutorial, we show how to implement the least squares approach to solve the Calderón problem in the noiseless setting. To be more precise, we wish to minimize the functional","category":"page"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"fsigmamapsto frac12Lambda(sigma)-Lambda(sigma^dagger)_2^2","category":"page"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"where sigma^dagger is an unknown conductivity. Since Lambda is nonlinear, f is non-convex and iterative minimization algorithms could in principle suffer from the problem of local convergence (their output might heavily depend on their initialization). However, we will see that, in practice, the main issue is rather the ill-posedness of the inverse problem, and that robust iterative algorithms almost always converge to a global minmizer regardless of their initialization.","category":"page"},{"location":"examples/least_squares/#Setting","page":"Least squares","title":"Setting","text":"","category":"section"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"using RadialCalderon\n\nn = 3\nr = [0.5, 0.25]\nforward = ForwardProblem(r)\n\nm = n\nΛ(σ) = [forward_map(forward, j, σ) for j in 1:m]  # forward map\n\na = 0.5\nb = 1.5\n\nσ_true = [0.8, 1.2, 1.0]  # unknown conductivity\nobs_true = Λ(σ_true);  # observations\nnothing #hide","category":"page"},{"location":"examples/least_squares/#Using-[NonlinearSolve.jl](https://github.com/SciML/NonlinearSolve.jl)","page":"Least squares","title":"Using NonlinearSolve.jl","text":"","category":"section"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"We use the package NonlinearSolve.jl to solve the equation Lambda(sigma)=Lambda(sigma^dagger) using a robust Newton-type algorithm initialized with a guess sigma_mathrminit. We notice that, in practice, the method converges to a solution regardless of its initialization.","category":"page"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"using Base.Iterators: product\n\nk = 5\nprod_it = product([range(a, b, k) for i=1:3]...)\nσ_init_tab = hcat(collect.(collect(prod_it))...)\nnσ_init = size(σ_init_tab, 2)\n\n@info \"Number of initializations: $nσ_init\"","category":"page"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"The set of initial guesses is a regular discretization of ab^n using k^n points (here, we chose k=5).","category":"page"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"using NonlinearSolve\n\nresidual(σ, p) = Λ(σ) .- obs_true\nmax_linf_err = 0.0\n\nfor i=1:nσ_init\n    σ_init = σ_init_tab[:, i]\n    problem = NonlinearProblem(residual, σ_init)\n    res = NonlinearSolve.solve(problem, RobustMultiNewton())\n    σ_hat = res.u\n    global max_linf_err = max(max_linf_err, maximum(abs.(σ_hat .- σ_true)))\nend\n\n@info \"Maximum l-infinity error: $max_linf_err\"","category":"page"},{"location":"examples/least_squares/#Using-[Optimization.jl](https://github.com/SciML/Optimization.jl)","page":"Least squares","title":"Using Optimization.jl","text":"","category":"section"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"We can also use the Optimization.jl package to call a large list of optimization algorithms to minimize f. Here, we use the BFGS algorithm from the Optim.jl package.","category":"page"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"using Optimization\nusing OptimizationOptimJL\n\nobj(σ, p) = 0.5 * sum((Λ(σ) .- obs_true).^2)\noptfun = OptimizationFunction(obj, Optimization.AutoForwardDiff())\n\nmax_linf_err = 0.0\n\nfor i=1:nσ_init\n    σ_init = σ_init_tab[:, i]\n    problem = OptimizationProblem(optfun, σ_init)\n    res = solve(problem, Optim.BFGS(), g_tol=1e-14)\n    σ_hat = res.u\n    global max_linf_err = max(max_linf_err, maximum(abs.(σ_hat .- σ_true)))\nend\n\n@info \"Maximum l-infinity error: $max_linf_err\"","category":"page"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"","category":"page"},{"location":"examples/least_squares/","page":"Least squares","title":"Least squares","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#RadialCalderon.jl","page":"Home","title":"RadialCalderon.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Dev) (Image: Aqua QA) (Image: Build Status)","category":"page"},{"location":"","page":"Home","title":"Home","text":"A Julia package for studying the Calderon problem with piecewise constant radial conductivities.","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install this package, run the following command from the REPL in Pkg mode.","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add https://github.com/rpetit/RadialCalderon.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"Tutorials and examples are available in the documentation.","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use this package in your research, please cite the following preprint.","category":"page"},{"location":"","page":"Home","title":"Home","text":"@misc{ClariceGiovanniRomain2025,\n    title = {On the non-convexity issue in the radial Calder{\\'o}n problem},\n    author = {Clarice, Giovanni, Romain},\n    year = {2025},\n    number = {arXiv:0000.00000},\n    eprint = {0000.00000},\n    primaryclass = {math},\n    publisher = {arXiv}\n}","category":"page"},{"location":"examples/nonlinear_sdp/#Reconstruction-via-convex-programming","page":"Convex nonlinear SDP","title":"Reconstruction via convex programming","text":"","category":"section"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"In this tutorial, we show how to implement in practice the reconstruction method introduced in (Harrach, 2023). It is based on the resolution of a convex nonlinear semidefinite program of the form","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"undersetsigmainab^nmathrmminlangle csigmaranglemathrmstLambda(sigma)leq y","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"where c is a weight vector with positive entries and y is the vector of observations. If the number of measurements m is large enough, then there exists a vector c such that, for every sigma^daggerinab^n, the above problem with y=Lambda(sigma^dagger) has a unique solution which is sigma^dagger.","category":"page"},{"location":"examples/nonlinear_sdp/#Setting","page":"Convex nonlinear SDP","title":"Setting","text":"","category":"section"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"We define the forward problem. There are two annuli with the inner radius being 0.5.","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"using RadialCalderon\n\nn = 2\nr = [0.5]\nforward = ForwardProblem(r)\n\na = 0.5\nb = 1.5;\nnothing #hide","category":"page"},{"location":"examples/nonlinear_sdp/#Estimation-of-the-weight-vector","page":"Convex nonlinear SDP","title":"Estimation of the weight vector","text":"","category":"section"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"For a given m, one can try to find a universal vector c by solving a feasibility problem constructed via build_c_estimation_problem. Below, we check that, when n=2, this is possible for m=3 but not for m=2. First, we define a set of conductivities which will be used to estimate c.","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"using Base.Iterators: product\n\nk = 2\n\nprod_it = product([range(a, b, k) for i=1:forward.n]...)\nσ = hcat(collect.(collect(prod_it))...)\nσ = σ[:, 1:end-1];  # remove b*ones(n)\nnothing #hide","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"We build the c estimation problem for m=2 and check that it is not feasible. The problem is a linear program, so that any suitable solver other than Ipopt can be used (in our experiments, MOSEK performed best).","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"using JuMP\nimport Ipopt\n\nm = 2\nmodel = build_c_estimation_problem(σ, a, b, m, forward)\noptimizer = optimizer_with_attributes(Ipopt.Optimizer, \"print_level\" => 0, \"sb\" => \"yes\")\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"We check that there is no admissible vector c for m=2.","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"is_solved_and_feasible(model)","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"We check that there is an admissible vector c for m=3.","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"m = 3\nmodel = build_c_estimation_problem(σ, a, b, m, forward)\nset_optimizer(model, optimizer)\noptimize!(model)\nis_solved_and_feasible(model)","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"The estimated vector c can be accessed as follows.","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"c = value.(model[:c])","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"We stress that, when n is larger, the tolerance of the solver might have to be adjusted to ensure that the problem is solved with good precision.","category":"page"},{"location":"examples/nonlinear_sdp/#Resolution-of-the-convex-nonlinear-SDP","page":"Convex nonlinear SDP","title":"Resolution of the convex nonlinear SDP","text":"","category":"section"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"Once the weight vector c is estimated, one can solve the convex nonlinear SDP defined above. To do so, we build the problem using build_nonlinear_sdp and use the Optimization package with the Ipopt solver.","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"using Optimization, OptimizationMOI\n\nσ_true = [0.8, 1.2]  # unknown conductivity\nobs = [forward_map(forward, j, σ_true) for j=1:m]  # observations\nproblem = ConvexCalderonProblem(c, a, b, obs, forward)\n\nσ_init = (0.9*b) .* ones(forward.n)  # intial guess\nprob = build_nonlinear_sdp(problem, σ_init)  # container for the nonlinear SDP\n\noptimizer = OptimizationMOI.MOI.OptimizerWithAttributes(\n    Ipopt.Optimizer,\n    \"print_level\" => 0,\n    \"sb\" => \"yes\"\n)\n\nsol = solve(prob, optimizer)\nσ_hat = sol.u\n\nisapprox(σ_hat, σ_true, rtol=1e-6)","category":"page"},{"location":"examples/nonlinear_sdp/#References","page":"Convex nonlinear SDP","title":"References","text":"","category":"section"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"Harrach, B. (2023). The Calderón Problem with Finitely Many Unknowns Is Equivalent to Convex Semidefinite Optimization. SIAM Journal on Mathematical Analysis, 5666–5684.\n\n\n\n","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"","category":"page"},{"location":"examples/nonlinear_sdp/","page":"Convex nonlinear SDP","title":"Convex nonlinear SDP","text":"This page was generated using Literate.jl.","category":"page"}]
}
